{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8110c9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "addresses = {}\n",
    "\n",
    "# Load the JSON file\n",
    "with open('../output/addresses.json', 'r', encoding='utf-8') as file:\n",
    "    addresses = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "19f3e611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addresses without 'Romania':\n"
     ]
    }
   ],
   "source": [
    "# filter out null or None values\n",
    "addresses = {k: v for k, v in addresses.items() if v is not None and v != 'null' and v != ''}\n",
    "\n",
    "romania_addresses = {}\n",
    "other_addresses = {}\n",
    "# extract addresses with 'Romania' in the value. \n",
    "for account, value in addresses.items():\n",
    "    # Replace all special characters (ăââßîșț) with their ASCII equivalents\n",
    "    ascii_value = value.encode('ascii', 'ignore').decode('ascii')\n",
    "    if 'Romania' in ascii_value:\n",
    "        romania_addresses[account] = ascii_value\n",
    "    else:\n",
    "        other_addresses[account] = ascii_value\n",
    "        \n",
    "\n",
    "# Print the rest\n",
    "print(\"Addresses without 'Romania':\")\n",
    "# for account, value in other_addresses.items():\n",
    "    #print(f\"{account}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f15ca99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "\n",
    "def hash_text(text):\n",
    "    \"\"\"\n",
    "    Hash the comment text to create a unique identifier.\n",
    "    \"\"\"\n",
    "    # Normalize to NFKD form and encode to ASCII, ignoring non-ASCII characters\n",
    "    normalized_text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('ascii')\n",
    "\n",
    "    # Remove all characters except a-z and 0-9\n",
    "    cleaned_text = re.sub(r'[^a-z0-9]', '', normalized_text.lower())\n",
    "    # Hash the cleaned text using SHA-256\n",
    "    return hashlib.sha256(cleaned_text.encode('utf-8')).hexdigest().upper()\n",
    "\n",
    "# Create a dictionary to store the hashes and their corresponding addresses\n",
    "hashes = {}\n",
    "for account, value in other_addresses.items():\n",
    "    # Hash the address value\n",
    "    address_hash = hash_text(value)\n",
    "    # Store the hash and the address in the dictionary\n",
    "    if address_hash not in hashes:\n",
    "        hashes[address_hash] = {\n",
    "            'address': value,\n",
    "            'count': 1,\n",
    "            'accounts': [account]\n",
    "        }\n",
    "    else:\n",
    "        hashes[address_hash]['count'] += 1\n",
    "        hashes[address_hash]['accounts'].append(account)\n",
    "\n",
    "# save the hashes to a JSON file, ordered by count\n",
    "with open('../output/address_summary.json', 'w', encoding='utf-8') as file:\n",
    "    # Sort the hashes by count in descending order\n",
    "    sorted_hashes = dict(sorted(hashes.items(), key=lambda item: item[1]['count'], reverse=True))\n",
    "    # Write the sorted hashes to the JSON file\n",
    "    json.dump(sorted_hashes, file, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f1103c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2176"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 📦 Asigură-te că ai rapidfuzz instalat\n",
    "# !pip install rapidfuzz\n",
    "\n",
    "from rapidfuzz import fuzz\n",
    "from collections import defaultdict\n",
    "\n",
    "# 📌 Exemplu de structură: {\"url1\": \"Adresa 1\", \"url2\": \"Adresa 2\", ...}\n",
    "# other_addresses = {...}\n",
    "# 📦 Dacă nu ai rapidfuzz instalat:\n",
    "# !pip install rapidfuzz\n",
    "\n",
    "import json\n",
    "from rapidfuzz import fuzz\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "# Încarcă datele\n",
    "with open(\"../output/augmented_accounts.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Transform url in other_addresses (the key is the url) and remove the `about` part. (either \\about either &sk=about)\n",
    "def normalize_facebook_url(url: str) -> str:\n",
    "    if \"/about\" in url:\n",
    "        return url.split(\"/about\")[0]\n",
    "    if \"?sk=about\" in url:\n",
    "        return url.split(\"&sk=about\")[0]\n",
    "    return url.rstrip(\"/\")\n",
    "\n",
    "normalized_other_addresses = {}\n",
    "for url, address in other_addresses.items():\n",
    "    clean_url = normalize_facebook_url(url)\n",
    "    normalized_other_addresses[clean_url] = address  # may overwrite duplicates\n",
    "\n",
    "# Copy back to the original dictionary\n",
    "other_addresses = normalized_other_addresses\n",
    "   \n",
    "# Extrage mapping-ul URL → adresă și URL → nume\n",
    "url_to_name = {}\n",
    "\n",
    "for account in data[\"accounts\"]:\n",
    "    url = account[\"profile_url\"]\n",
    "    name = account[\"name\"]\n",
    "    address = account.get(\"address\", \"\").strip()\n",
    "    url_to_name[url] = name\n",
    "\n",
    "# Normalizează adresele pentru comparare fuzzy\n",
    "normalized = {url: addr.lower().replace(\",\", \"\").strip() for url, addr in other_addresses.items()}\n",
    "\n",
    "urls = list(normalized.keys())\n",
    "visited = set()\n",
    "groups = defaultdict(list)\n",
    "SIMILARITY_THRESHOLD = 80\n",
    "\n",
    "# Grupează adresele similare\n",
    "for i, url_i in enumerate(urls):\n",
    "    if url_i in visited:\n",
    "        continue\n",
    "    group = [url_i]\n",
    "    visited.add(url_i)\n",
    "    addr_i = normalized[url_i]\n",
    "    for j in range(i + 1, len(urls)):\n",
    "        url_j = urls[j]\n",
    "        if url_j in visited:\n",
    "            continue\n",
    "        addr_j = normalized[url_j]\n",
    "        similarity = fuzz.ratio(addr_i, addr_j)\n",
    "        if similarity >= SIMILARITY_THRESHOLD:\n",
    "            group.append(url_j)\n",
    "            visited.add(url_j)\n",
    "    groups[url_i] = group\n",
    "\n",
    "# Sortează grupurile descrescător, după numărul de conturi\n",
    "sorted_groups = sorted(groups.items(), key=lambda item: len(item[1]), reverse=True)\n",
    "\n",
    "# Remove groups with less than 2 accounts\n",
    "sorted_groups = [(leader_url, group_urls) for leader_url, group_urls in sorted_groups if len(group_urls) > 1]\n",
    "\n",
    "# Generează conținutul raportului în limba română\n",
    "report_lines = [\"# 📍 Gruparea conturilor după adresă (top)\\n\"]\n",
    "\n",
    "report_lines.append(\"Acest raport conține grupuri de conturi Facebook care au adrese similare. Adresele sunt normalizate pentru a elimina variațiile minore.\\n\")\n",
    "\n",
    "report_lines.append(\"Sunt incluse doar grupurile cu mai mult de 1 cont.\")\n",
    "\n",
    "\n",
    "for leader_url, group_urls in sorted_groups:\n",
    "    address = other_addresses[leader_url]\n",
    "    report_lines.append(f\"\\n## {address}  \\n**{len(group_urls)} conturi asociate**:\\n\")\n",
    "    for url in group_urls:\n",
    "        name = url_to_name.get(url, \"Nume necunoscut\")\n",
    "        report_lines.append(f\"- [{name}]({url})\")\n",
    "\n",
    "# Salvează raportul în fișierul Markdown\n",
    "report_path = Path(\"../reports/report-top-other-addresses.md\")\n",
    "report_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "report_path.write_text(\"\\n\".join(report_lines), encoding=\"utf-8\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
